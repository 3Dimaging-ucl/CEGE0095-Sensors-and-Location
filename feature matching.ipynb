{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interest Points and Matching\n",
    "\n",
    "We will go through the steps of matching interest / key points from one image to another (left to right). We use OpenCV for this task, an open source image processing library. We also use matplotlib to display the images within this notebook. First we load the images and convert them to grayscale images. The we extract the keypoint locations and the SIFT descriptor for every location. In the final step we match the features according by the Euclidean distance (L2 norm) of their descriptors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "print('OpenCV version: {}'.format(cv2.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Open CV is a image processing library. install with\n",
    "# pip install opencv-python\n",
    "left = cv2.imread(r'Picture2.png')\n",
    "right = cv2.imread(r'Picture3.png')\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(left)\n",
    "plt.show()\n",
    "\n",
    "print('Left image size: {}'.format(left.shape))\n",
    "print('Right image size: {}'.format(right.shape))\n",
    "\n",
    "# convert to greyscale\n",
    "left_g = cv2.cvtColor(left, cv2.COLOR_BGR2GRAY)\n",
    "right_g = cv2.cvtColor(right, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract key-points and descriptors using SIFT (Scale-Invariant Feature Transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sift is copyrighted. install with\n", 
    "# pip install opencv-contrib-python\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "left_p, left_d = sift.detectAndCompute(left_g, None)\n",
    "right_p, right_d = sift.detectAndCompute(right_g, None)\n",
    "\n",
    "result = cv2.drawKeypoints(left, left_p, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(result)\n",
    "plt.show()\n",
    "\n",
    "print('no. of SIFT keypoints left: {}, right:{}'.format(len(left_p), len(right_p)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: Extract key-points and descriptors using ORB (Oriented FAST and Rotated BRIEF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ORB is limited to 500 feature points by default (can be changed)\n",
    "#orb = cv2.ORB_create(nfeatures=500)\n",
    "#left_p, left_d = orb.detectAndCompute(left_g, None)\n",
    "#right_p, right_d = orb.detectAndCompute(right_g, None)\n",
    "\n",
    "#print('no. of keypoints left: {}, right:{}'.format(len(left_p), len(right_p)))\n",
    "\n",
    "# remember we need to use a differnt distance norm for matching later as ORB is a binary desriptor\n",
    "#matcher = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True) # so called brute force (BF) matcher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True) # so called brute force (BF) matcher\n",
    "matches = matcher.match(left_d, right_d)\n",
    "\n",
    "print('no. of matches: {}'.format(len(matches)))\n",
    "\n",
    "# Sort the matches by Euclidean distance\n",
    "matches = sorted(matches, key=lambda x:x.distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show matches\n",
    " Show the matches (only the first n=50) by drawing a line from keypoints in the left image to matched keypoints in teh right image "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=50\n",
    "result = cv2.drawMatches(left_g, left_p, right_g, right_p, matches[:n], \n",
    "                         None, (256, 0, 0), flags=2)\n",
    "plt.figure(figsize = (20,20))\n",
    "plt.imshow(result)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tasks\n",
    "* How can you quickly judge if the matches are correct or not?\n",
    "* Start from Picture 2 and successively match to 3 and 4. Do you see a change in the quality of the matches?\n",
    "* The matching does not use the ratio criterion suggested by Lowe. Can you implement it?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
